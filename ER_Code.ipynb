{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BUKhZ53SlD3",
    "outputId": "055f24b0-dd0f-487a-8b31-2a0708027cd4"
   },
   "outputs": [],
   "source": [
    "!pip3 install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqXkWgbSc6yx"
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "import seaborn as sns\n",
    "import scikitplot\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import Dense,Flatten,Dropout\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator ,load_img\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import requests\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dcj4OUSvc6yy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "k1trzH5ic6yy",
    "outputId": "cc5c5922-7a1a-44f4-8da2-daa6825eb98d"
   },
   "outputs": [],
   "source": [
    "#Importing Data from CSV file\n",
    "fer_dataset = pd.read_csv(\"./fer2013.csv\")\n",
    "fer_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Dh-Kaxjc6yy"
   },
   "outputs": [],
   "source": [
    "emotion_labels=fer_dataset.iloc[:,[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaTwloO2c6yy"
   },
   "outputs": [],
   "source": [
    "pixels=fer_dataset['pixels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7IL_wkic6yy",
    "outputId": "0186a65a-0033-4988-ea71-12d4102b6d79"
   },
   "outputs": [],
   "source": [
    "#Facial Expressions\n",
    "Expressions = {0:\"Angry\",1:\"Disgust\",2:\"Fear\",3:\"Happy\",4:\"Sad\",5:\"Surprise\",6:\"Neutral\"}\n",
    "from keras.utils import to_categorical \n",
    "emotion_labels = to_categorical(emotion_labels,len(Expressions))\n",
    "print(emotion_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "id": "HeZayptobOHp",
    "outputId": "b732e382-272a-4063-9846-0a31bd6335f6"
   },
   "outputs": [],
   "source": [
    "sns.countplot(fer_dataset.emotion)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTRNT_lTc6yy"
   },
   "outputs": [],
   "source": [
    "#converting pixels to Gray Scale images of 48X48 \n",
    "\n",
    "images = np.array([np.fromstring(pixel, dtype=int, sep=\" \")for pixel in pixels])\n",
    "images = images/255.0\n",
    "images = images.reshape(images.shape[0],48,48,1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "Euzr3S4Cc6yy",
    "outputId": "031e6b08-9eb6-4d42-c788-05dd76c410ef"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0][:,:,0])\n",
    "Expressions[emotion_labels[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys2-yFiuc6yy"
   },
   "outputs": [],
   "source": [
    "#splitting data into training and test data\n",
    "train_images,test_images,train_labels,test_labels = train_test_split(images,emotion_labels,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvq_PPy_c6yy",
    "outputId": "9d82dde4-a98b-41fd-b294-2c2a622a218e"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Rii5xO_c6yy"
   },
   "outputs": [],
   "source": [
    "def create_convolutional_model(emotions):\n",
    "    seq_model = Sequential()\n",
    "    seq_model.add(Conv2D(32,kernel_size=(2,2),strides=(1,1),activation='relu',input_shape=(48,48,1)))\n",
    "    seq_model.add(BatchNormalization())\n",
    "    seq_model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    seq_model.add(Dropout(0.25))\n",
    "    \n",
    "    seq_model.add(Conv2D(filters=64,kernel_size=(2,2),strides=(1,1),activation='relu'))\n",
    "    seq_model.add(BatchNormalization())\n",
    "    seq_model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "    seq_model.add(Dropout(0.25))#to prevent neural network from overfitting\n",
    "    \n",
    "    seq_model.add(Conv2D(filters=128,kernel_size=(2,2),strides=(1,1),activation='relu'))\n",
    "    seq_model.add(BatchNormalization())\n",
    "    seq_model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "    seq_model.add(Dropout(0.25))\n",
    "    \n",
    "    seq_model.add(Conv2D(filters=256,kernel_size=(2,2),strides=(1,1),activation='relu'))\n",
    "    seq_model.add(BatchNormalization())\n",
    "    seq_model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "    seq_model.add(Dropout(0.25))\n",
    "    \n",
    "    seq_model.add(Flatten())\n",
    "    \n",
    "    seq_model.add(Dense(256,activation='relu'))\n",
    "    seq_model.add(BatchNormalization())\n",
    "    seq_model.add(Dropout(0.25))\n",
    "    \n",
    "    seq_model.add(Dense(512,activation='relu'))\n",
    "    seq_model.add(BatchNormalization())\n",
    "    seq_model.add(Dropout(0.25))\n",
    "    \n",
    "    seq_model.add(Dense(emotions,activation='softmax')) \n",
    "\n",
    "    seq_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return seq_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEbRJSmENvL9"
   },
   "outputs": [],
   "source": [
    "learn_rate = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    learn_rate,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6O0ZGwuPsw5"
   },
   "outputs": [],
   "source": [
    "# As the data in hand is less as compared to the task so ImageDataGenerator is good to go.\n",
    "data_augment = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "data_augment.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Glcftsm3c6yy",
    "outputId": "bd121ce4-5430-42d8-af34-da9fb2c5c34f"
   },
   "outputs": [],
   "source": [
    "emotions=7\n",
    "cnn_model = create_convolutional_model(emotions)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8V8CGkJdc6yy",
    "outputId": "2b0bc5f1-d65d-4efd-caf8-cf5b0b915e9f"
   },
   "outputs": [],
   "source": [
    "#train the CNN \n",
    "history = cnn_model.fit_generator(\n",
    "    data_augment.flow(train_images, train_labels, batch_size=105),\n",
    "    validation_data=(test_images, test_labels),\n",
    "    epochs=110,\n",
    "    callbacks=callbacks,verbose=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2C6sDgOfc6yz"
   },
   "outputs": [],
   "source": [
    "emotion_pred = cnn_model.predict(test_images)\n",
    "emotion_pred=np.argmax(emotion_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "qKy-p2JfM1oL",
    "outputId": "42fbfc6f-d302-45bf-af49-e41e5b8126c6"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "sns.set()\n",
    "fig = pyplot.figure(0, (12, 4))\n",
    "\n",
    "ax = pyplot.subplot(1, 2, 1)\n",
    "sns.lineplot(history.epoch, history.history['accuracy'], label='train')\n",
    "sns.lineplot(history.epoch, history.history['val_accuracy'], label='test')\n",
    "pyplot.title('Accuracy Graph')\n",
    "pyplot.tight_layout()\n",
    "\n",
    "ax = pyplot.subplot(1, 2, 2)\n",
    "sns.lineplot(history.epoch, history.history['loss'], label='train')\n",
    "sns.lineplot(history.epoch, history.history['val_loss'], label='test')\n",
    "pyplot.title('Loss Graph')\n",
    "pyplot.tight_layout()\n",
    "\n",
    "pyplot.savefig('epoch_history_dcnn.png')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 980
    },
    "id": "oYC00Pfac6yz",
    "outputId": "b3638f4e-0768-4fae-e98f-c20d9d13ba01"
   },
   "outputs": [],
   "source": [
    "#making confusion matrix\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, emotions, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(emotions))\n",
    "    plt.xticks(tick_marks, emotions, rotation=45)\n",
    "    plt.yticks(tick_marks, emotions)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "test_labels=np.argmax(test_labels,axis=1)\n",
    "cnf_matrix = confusion_matrix(test_labels,emotion_pred)\n",
    "class_names=Expressions\n",
    "# Plotting normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, emotions=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y86oLRDcc6yz"
   },
   "outputs": [],
   "source": [
    "#Save the weights\n",
    "weight_file='model_weights.hdf5'\n",
    "cnn_model.save_weights(weight_file,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBUeMMyRc6yz"
   },
   "outputs": [],
   "source": [
    "#Save the weights\n",
    "fileweight_filename='model_weights.hdf5'\n",
    "cnn_model.load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Z4BKdekBSJp"
   },
   "outputs": [],
   "source": [
    "# making folders\n",
    "\n",
    "import os \n",
    "outer_file = ['result']\n",
    "inner_file = ['Angry', 'Disgusted', 'Fearful', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "os.makedirs('data', exist_ok=True)\n",
    "for outer in outer_file:\n",
    "    os.makedirs(os.path.join('data',outer), exist_ok=True)\n",
    "    for inner in inner_file:\n",
    "        os.makedirs(os.path.join('data',outer,inner), exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTttkMi1c6yz"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def make_prediction(images):\n",
    "    images=cv2.resize(images,(48,48))\n",
    "    images=images/255.0\n",
    "    images=np.array(images).reshape(-1,48,48,1)\n",
    "    predict=np.argmax(cnn_model.predict(images),axis = 1)\n",
    "    return predict[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A97G2zkBtPU3"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "def face_in_img(imagePath):\n",
    "    face_cascadeFile = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "    img = cv2.imread(imagePath) \n",
    "    grayImage = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascadeFile.detectMultiScale(grayImage,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "            crop_face = grayImage[y:y+h, x:x+w]\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            res=make_prediction(crop_face)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            label_img=cv2.putText(img,str(Expressions[res]),(x,y-5),font,0.7,(205,200,50),2,cv2.LINE_AA)\n",
    "\n",
    "            if res == 0:\n",
    "              cv2.imwrite('./data/result/Angry/im'+Expressions[res]+'.png',label_img)\n",
    "            if res == 1:\n",
    "              cv2.imwrite('./data/result/Disgust/im'+Expressions[res]+'.png',label_img)\n",
    "            if res == 2:\n",
    "              cv2.imwrite('./data/result/Fear/im'+Expressions[res]+'.png',label_img)\n",
    "            if res == 3:\n",
    "              cv2.imwrite('./data/result/Happy/im'+Expressions[res]+'.png',label_img)\n",
    "            if res == 4:\n",
    "              cv2.imwrite('./data/result/Sad/im'+Expressions[res]+'.png',label_img)\n",
    "            if res == 5:\n",
    "              cv2.imwrite('./data/result/Surprise/im'+Expressions[res]+'.png',label_img)\n",
    "            if res == 6:\n",
    "              cv2.imwrite('./data/result/Neutral/im'+Expressions[res]+'.png',label_img)\n",
    "                 \n",
    "    cv2_imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "id": "fhcmzl09Vn9u",
    "outputId": "4842b07a-ce7d-49ac-b1bc-d823497cdf7e"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "path = './test_images'\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "for item in dirs:\n",
    "  if path+item:\n",
    "    im= cv2.imread(path+'/'+item) \n",
    "    face_in_img(path+'/'+item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hk3vPsbE-qtv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import requests\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-EX7nEh-t6E"
   },
   "outputs": [],
   "source": [
    "anotationFile='./instances_val2017.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2nwKt5Q-2rU",
    "outputId": "057d364a-c359-44a3-8d85-889a342c8669"
   },
   "outputs": [],
   "source": [
    "cocodata=COCO(anotationFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEMxPh2h_JGF",
    "outputId": "637787fd-3823-4a33-ab10-30596b1dc6ce"
   },
   "outputs": [],
   "source": [
    "# display COCO categories and supercategories\n",
    "cats = cocodata.loadCats(cocodata.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWp3jHxL_R62",
    "outputId": "eebf56f0-b33e-43c7-c0d1-c610a5cd3252"
   },
   "outputs": [],
   "source": [
    "# get all images containing given categories, select one at random\n",
    "categ_Ids = cocodata.getCatIds(catNms=['person']);\n",
    "imageIds = cocodata.getImgIds(catIds=categ_Ids );\n",
    "images = cocodata.loadImgs(imageIds)\n",
    "print(\"Number of images containing all the  classes:\", len(imageIds))\n",
    "\n",
    "img = cocodata.loadImgs(imageIds[np.random.randint(0,len(imageIds))])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "rq30Gnt2_ase",
    "outputId": "55b41650-fa81-48a1-f487-b6bbb245a516"
   },
   "outputs": [],
   "source": [
    "# use url to load image\n",
    "I = io.imread(img['coco_url'])\n",
    "plt.axis('off')\n",
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjRiCLqU_ewe"
   },
   "outputs": [],
   "source": [
    "#Loading images in a folder\n",
    "os.makedirs('coco_images', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "xpGTVXx7_4Qz",
    "outputId": "e7ee75c3-5908-4e15-960c-0ecfec3d8429"
   },
   "outputs": [],
   "source": [
    "for im in images:\n",
    "    #print(\"im: \", im)\n",
    "    coco_img = requests.get(im['coco_url']).content\n",
    "    with open('coco_images/' + im['file_name'], 'wb') as handler:\n",
    "        handler.write(coco_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZTC4w8tFAEDk",
    "outputId": "e516b419-8737-459b-f5f9-27885b03f840"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "coco_imgpath = './coco_images'\n",
    "dirs = os.listdir(coco_imgpath)\n",
    "\n",
    "for item in dirs:\n",
    "  if coco_imgpath+item:\n",
    "    im= cv2.imread(coco_imgpath+'/'+item) \n",
    "    face_in_img(coco_imgpath+'/'+item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YPtYRtUUWU7"
   },
   "outputs": [],
   "source": [
    "## References\n",
    "\n",
    "\n",
    "# https://medium.com/themlblog/how-to-do-facial-emotion-recognition-using-a-cnn-b7bbae79cd8f\n",
    "# https://github.com/serengil/tensorflow-101/blob/master/python/facial-expression-recognition.py\n",
    "# https://www.kaggle.com/jonathanoheix/face-expression-recognition-dataset\n",
    "# https://analyticsindiamag.com/my-first-cnn-project-emotion-detection-using-convolutional-neural-network-with-tpu/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of FinalProject_Team18Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
